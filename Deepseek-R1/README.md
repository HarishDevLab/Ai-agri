# THE MAIN LLM FOR THINKING

THE MODEL WE PREFERED IS DEEPSEEEK R1 8BIT QUANTIZED MODEL ( FITS WELL FOR COLLAB WITH HIGH REASINING ABILITY )
----------------------------------------------------
**DISCUSSIONS AND IDEAS ARE ALWAYS WELCOME**
